
```shell
python run.py
```
```shell
 --batch BATCH  Training Batch size default: 100
  --iters ITERS  Number of training iterations default: 3000
  --lr LR        Model learning rate default: 0.1
  --clip CLIP    gradient clipping default: 1
  --load LOAD    True: Load trained model False: Train model default: True
```

### Recurrent (ReLU Activation, One Layer, 5 epochs,3000 iteration)
```text
Iteration: 500 Loss: 1.3418495655059814 Accuracy 40.13
Iteration: 1000 Loss: 0.7700706720352173 Accuracy 62.19
Iteration: 1500 Loss: 1.1213867664337158 Accuracy 81.23
Iteration: 2000 Loss: 0.7049544453620911 Accuracy 86.21
Iteration: 2500 Loss: 0.3671818673610687 Accuracy 88.78
Iteration: 3000 Loss: 0.3177652060985565 Accuracy 92.23
```

### Recurrent (ReLU Activation, Two Layer, 5 epochs, 3000 iteration)
```text
Iteration: 500 Loss: 0.9008259773254395 Accuracy 62.98
Iteration: 1000 Loss: 0.5199368000030518 Accuracy 78.67
Iteration: 1500 Loss: 0.5504856705665588 Accuracy 88.13
Iteration: 2000 Loss: 0.5846810936927795 Accuracy 92.59
Iteration: 2500 Loss: 0.2567622661590576 Accuracy 93.19
Iteration: 3000 Loss: 0.2928905785083771 Accuracy 94.85
```


### Recurrent (ReLU Activation, Two Layer,10 epochs, 6000 iteration)
```text
Iteration: 500 Loss: 0.9008259773254395 Accuracy 62.98
Iteration: 1000 Loss: 0.5199368000030518 Accuracy 78.67
Iteration: 1500 Loss: 0.5504856705665588 Accuracy 88.13
Iteration: 2000 Loss: 0.5846810936927795 Accuracy 92.59
Iteration: 2500 Loss: 0.2567622661590576 Accuracy 93.19
Iteration: 3000 Loss: 0.2928905785083771 Accuracy 94.85
Iteration: 3500 Loss: 0.0961369052529335 Accuracy 96.1
Iteration: 4000 Loss: 0.12104305624961853 Accuracy 96.11
Iteration: 4500 Loss: 0.16882425546646118 Accuracy 96.57
Iteration: 5000 Loss: 0.21620489656925201 Accuracy 95.87
Iteration: 5500 Loss: 0.15809383988380432 Accuracy 96.23
Iteration: 6000 Loss: 0.30511119961738586 Accuracy 97.62
```

### Recurrent (Tanh Activation, Two Layer,10 epochs, 6000 iteration)
```text
Iteration: 500 Loss: 0.7264447212219238 Accuracy 70.01
Iteration: 1000 Loss: 0.42540374398231506 Accuracy 86.96
Iteration: 1500 Loss: 0.28621986508369446 Accuracy 89.98
Iteration: 2000 Loss: 0.2150164395570755 Accuracy 93.4
Iteration: 2500 Loss: 0.19931384921073914 Accuracy 94.39
Iteration: 3000 Loss: 0.11196047067642212 Accuracy 94.25
Iteration: 3500 Loss: 0.12797145545482635 Accuracy 95.93
Iteration: 4000 Loss: 0.13971655070781708 Accuracy 96.32
Iteration: 4500 Loss: 0.12669919431209564 Accuracy 96.39
Iteration: 5000 Loss: 0.24520301818847656 Accuracy 96.46
Iteration: 5500 Loss: 0.10133538395166397 Accuracy 97.14
Iteration: 6000 Loss: 0.13402363657951355 Accuracy 97.28
```

### Recurrent (ReLU Activation, Two Layer,10 epochs, 128 hidden, 6000 iteration)
```
Iteration: 500 Loss: 0.9200006723403931 Accuracy 65.84
Iteration: 1000 Loss: 0.6433969140052795 Accuracy 80.4
Iteration: 1500 Loss: 0.3651816248893738 Accuracy 84.88
Iteration: 2000 Loss: 0.4467617869377136 Accuracy 92.1
Iteration: 2500 Loss: 0.3688356876373291 Accuracy 92.43
Iteration: 3000 Loss: 0.11550597101449966 Accuracy 95.53
Iteration: 3500 Loss: 0.18532972037792206 Accuracy 95.61
Iteration: 4000 Loss: 0.12741021811962128 Accuracy 96.4
Iteration: 4500 Loss: 0.10100510716438293 Accuracy 95.96
Iteration: 5000 Loss: 0.09450361132621765 Accuracy 97.15
Iteration: 5500 Loss: 0.08160116523504257 Accuracy 97.28
Iteration: 6000 Loss: 0.02370297908782959 Accuracy 96.61
```
<!--![Figure_0.png](figures/Figure_0.png)  ![Figure_1.png](figures/Figure_1.png)-->

<!--![Figure_2.png](figures/Figure_2.png) ![Figure_3.png](figures/Figure_3.png)-->

<!--![Figure_4.png](figures/Figure_4.png) ![Figure_5.png](figures/Figure_5.png)-->

<!--![Figure_6.png](figures/Figure_6.png) ![Figure_7.png](figures/Figure_7.png)-->

<!--![Figure_8.png](figures/Figure_8.png) ![Figure_9.png](figures/Figure_9.png)-->

